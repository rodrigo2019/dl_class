{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura do conjunto de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>battery_power</th>\n",
       "      <th>blue</th>\n",
       "      <th>clock_speed</th>\n",
       "      <th>dual_sim</th>\n",
       "      <th>fc</th>\n",
       "      <th>four_g</th>\n",
       "      <th>int_memory</th>\n",
       "      <th>m_dep</th>\n",
       "      <th>mobile_wt</th>\n",
       "      <th>n_cores</th>\n",
       "      <th>...</th>\n",
       "      <th>px_height</th>\n",
       "      <th>px_width</th>\n",
       "      <th>ram</th>\n",
       "      <th>sc_h</th>\n",
       "      <th>sc_w</th>\n",
       "      <th>talk_time</th>\n",
       "      <th>three_g</th>\n",
       "      <th>touch_screen</th>\n",
       "      <th>wifi</th>\n",
       "      <th>price_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>794</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>106</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1222</td>\n",
       "      <td>1890</td>\n",
       "      <td>668</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1965</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0.2</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>915</td>\n",
       "      <td>1965</td>\n",
       "      <td>2032</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.7</td>\n",
       "      <td>108</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>868</td>\n",
       "      <td>1632</td>\n",
       "      <td>3057</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1512</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0.1</td>\n",
       "      <td>145</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>336</td>\n",
       "      <td>670</td>\n",
       "      <td>869</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.9</td>\n",
       "      <td>168</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>483</td>\n",
       "      <td>754</td>\n",
       "      <td>3919</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      battery_power  blue  clock_speed  dual_sim  fc  four_g  int_memory  \\\n",
       "1995            794     1          0.5         1   0       1           2   \n",
       "1996           1965     1          2.6         1   0       0          39   \n",
       "1997           1911     0          0.9         1   1       1          36   \n",
       "1998           1512     0          0.9         0   4       1          46   \n",
       "1999            510     1          2.0         1   5       1          45   \n",
       "\n",
       "      m_dep  mobile_wt  n_cores  ...  px_height  px_width   ram  sc_h  sc_w  \\\n",
       "1995    0.8        106        6  ...       1222      1890   668    13     4   \n",
       "1996    0.2        187        4  ...        915      1965  2032    11    10   \n",
       "1997    0.7        108        8  ...        868      1632  3057     9     1   \n",
       "1998    0.1        145        5  ...        336       670   869    18    10   \n",
       "1999    0.9        168        6  ...        483       754  3919    19     4   \n",
       "\n",
       "      talk_time  three_g  touch_screen  wifi  price_range  \n",
       "1995         19        1             1     0            0  \n",
       "1996         16        1             1     1            2  \n",
       "1997          5        1             1     0            3  \n",
       "1998         19        1             1     1            0  \n",
       "1999          2        1             1     1            3  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_train = pd.read_csv(\"./mobile_train.csv\")\n",
    "data_train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessamento\n",
    "### Separação dos dados de entrada e saída\n",
    "* Quais features serão as feature de entrada? (x)\n",
    "* Qual a features que vamos tentar prever? (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 3998.0 min: 0.0\n",
      "(2000, 20)\n",
      "(2000,)\n",
      "[1. 2. 2. ... 3. 0. 3.]\n"
     ]
    }
   ],
   "source": [
    "train_x = data_train.values[..., :20]\n",
    "train_y = data_train.values[..., -1]\n",
    "\n",
    "print(\"max:\", train_x.max(), \"min:\",  train_x.min())\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessamento\n",
    "### normalização dos valores\n",
    "* Qual preprocessamento aplicado na entrada? (x)\n",
    "* Qual preprocessamento aplicado na saída? (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 1.0000000000000002 min: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "normalizer = MinMaxScaler()\n",
    "train_x_normalized = normalizer.fit_transform(train_x)\n",
    "\n",
    "print(\"max:\", train_x_normalized.max(), \"min:\",  train_x_normalized.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoder\n",
    "![One_Hot_Encoder](images/one_hot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train y:\n",
      " [[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "train_y_oh = ohe.fit_transform(train_y.reshape(-1, 1)).toarray()\n",
    "\n",
    "\n",
    "print(\"train y:\\n\", train_y_oh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criação da rede neural com tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                672       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 36        \n",
      "=================================================================\n",
      "Total params: 1,372\n",
      "Trainable params: 1,372\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Input(20))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilação e treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3808 - accuracy: 0.2438 - val_loss: 1.3483 - val_accuracy: 0.2975\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 1.2385 - accuracy: 0.3406 - val_loss: 1.0632 - val_accuracy: 0.3675\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.8562 - accuracy: 0.6413 - val_loss: 0.6754 - val_accuracy: 0.7850\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5578 - accuracy: 0.8050 - val_loss: 0.5013 - val_accuracy: 0.8150\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4275 - accuracy: 0.8456 - val_loss: 0.3907 - val_accuracy: 0.8700\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3503 - accuracy: 0.8756 - val_loss: 0.3345 - val_accuracy: 0.8800\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2997 - accuracy: 0.8963 - val_loss: 0.2906 - val_accuracy: 0.8925\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2600 - accuracy: 0.9119 - val_loss: 0.3294 - val_accuracy: 0.8550\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2418 - accuracy: 0.9094 - val_loss: 0.2397 - val_accuracy: 0.9150\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2072 - accuracy: 0.9337 - val_loss: 0.2403 - val_accuracy: 0.9125\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1904 - accuracy: 0.9344 - val_loss: 0.2266 - val_accuracy: 0.9200\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1890 - accuracy: 0.9356 - val_loss: 0.2280 - val_accuracy: 0.9000\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1757 - accuracy: 0.9375 - val_loss: 0.2232 - val_accuracy: 0.9075\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9312 - val_loss: 0.2065 - val_accuracy: 0.9000\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9494 - val_loss: 0.1926 - val_accuracy: 0.9200\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.94 - 1s 3ms/step - loss: 0.1506 - accuracy: 0.9431 - val_loss: 0.2094 - val_accuracy: 0.9075\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1370 - accuracy: 0.9463 - val_loss: 0.2446 - val_accuracy: 0.8800\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1415 - accuracy: 0.9469 - val_loss: 0.1913 - val_accuracy: 0.9275\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1310 - accuracy: 0.9531 - val_loss: 0.1952 - val_accuracy: 0.9150\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9525 - val_loss: 0.1585 - val_accuracy: 0.9375\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1169 - accuracy: 0.9556 - val_loss: 0.1494 - val_accuracy: 0.9475\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1111 - accuracy: 0.9638 - val_loss: 0.1529 - val_accuracy: 0.9350\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9600 - val_loss: 0.1752 - val_accuracy: 0.9175\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9606 - val_loss: 0.1582 - val_accuracy: 0.9225\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1067 - accuracy: 0.9575 - val_loss: 0.1504 - val_accuracy: 0.9275\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9644 - val_loss: 0.1565 - val_accuracy: 0.9300\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.0963 - accuracy: 0.9650 - val_loss: 0.1471 - val_accuracy: 0.9375\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.9581 - val_loss: 0.2177 - val_accuracy: 0.9075\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0923 - accuracy: 0.9663 - val_loss: 0.1510 - val_accuracy: 0.9350\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.0965 - accuracy: 0.9619 - val_loss: 0.1432 - val_accuracy: 0.9500\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.0901 - accuracy: 0.9656 - val_loss: 0.1667 - val_accuracy: 0.9275\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.0825 - accuracy: 0.9706 - val_loss: 0.1364 - val_accuracy: 0.9500\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0961 - accuracy: 0.9638 - val_loss: 0.1732 - val_accuracy: 0.9300\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.0916 - accuracy: 0.9638 - val_loss: 0.1514 - val_accuracy: 0.9225\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.0811 - accuracy: 0.9706 - val_loss: 0.1496 - val_accuracy: 0.9350\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.0721 - accuracy: 0.9750 - val_loss: 0.1426 - val_accuracy: 0.9425\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 0s 968us/step - loss: 0.0833 - accuracy: 0.9694 - val_loss: 0.1423 - val_accuracy: 0.9275\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 0s 960us/step - loss: 0.0682 - accuracy: 0.9744 - val_loss: 0.1698 - val_accuracy: 0.9325\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0665 - accuracy: 0.9794 - val_loss: 0.1281 - val_accuracy: 0.9475\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0625 - accuracy: 0.9769 - val_loss: 0.1238 - val_accuracy: 0.9500\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0657 - accuracy: 0.9806 - val_loss: 0.1327 - val_accuracy: 0.9500\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.0730 - accuracy: 0.9712 - val_loss: 0.1455 - val_accuracy: 0.9300\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0703 - accuracy: 0.9725 - val_loss: 0.1951 - val_accuracy: 0.9225\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 0.1333 - val_accuracy: 0.9400\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0615 - accuracy: 0.9806 - val_loss: 0.1806 - val_accuracy: 0.9250\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0680 - accuracy: 0.9744 - val_loss: 0.1266 - val_accuracy: 0.9450\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0576 - accuracy: 0.9844 - val_loss: 0.1705 - val_accuracy: 0.9125\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.0659 - accuracy: 0.9750 - val_loss: 0.2224 - val_accuracy: 0.8950\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0638 - accuracy: 0.9781 - val_loss: 0.1678 - val_accuracy: 0.9250\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9794 - val_loss: 0.1391 - val_accuracy: 0.9350\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0566 - accuracy: 0.9800 - val_loss: 0.1277 - val_accuracy: 0.9500\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0479 - accuracy: 0.9869 - val_loss: 0.1471 - val_accuracy: 0.9350\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 0s 947us/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.1299 - val_accuracy: 0.9400\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.0461 - accuracy: 0.9881 - val_loss: 0.1228 - val_accuracy: 0.9525\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0543 - accuracy: 0.9806 - val_loss: 0.1872 - val_accuracy: 0.9225\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0552 - accuracy: 0.9794 - val_loss: 0.1286 - val_accuracy: 0.9450\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 0s 943us/step - loss: 0.0470 - accuracy: 0.9875 - val_loss: 0.1907 - val_accuracy: 0.9175\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.1330 - val_accuracy: 0.9425\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0506 - accuracy: 0.9831 - val_loss: 0.2085 - val_accuracy: 0.9250\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0441 - accuracy: 0.9850 - val_loss: 0.1299 - val_accuracy: 0.9350\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.3271 - val_accuracy: 0.8900\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0542 - accuracy: 0.9794 - val_loss: 0.1556 - val_accuracy: 0.9400\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0393 - accuracy: 0.9856 - val_loss: 0.1352 - val_accuracy: 0.9425\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.1917 - val_accuracy: 0.9225\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0392 - accuracy: 0.9875 - val_loss: 0.2436 - val_accuracy: 0.9200\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0518 - accuracy: 0.9837 - val_loss: 0.1272 - val_accuracy: 0.9575\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.0370 - accuracy: 0.9875 - val_loss: 0.1615 - val_accuracy: 0.9175\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0355 - accuracy: 0.9900 - val_loss: 0.1688 - val_accuracy: 0.9325\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0376 - accuracy: 0.9881 - val_loss: 0.1310 - val_accuracy: 0.9475\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.2867 - val_accuracy: 0.9025\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0526 - accuracy: 0.9806 - val_loss: 0.1871 - val_accuracy: 0.9350\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0398 - accuracy: 0.9869 - val_loss: 0.1718 - val_accuracy: 0.9250\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.0428 - accuracy: 0.9862 - val_loss: 0.1326 - val_accuracy: 0.9350\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 0s 983us/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 0.1686 - val_accuracy: 0.9325\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.0306 - accuracy: 0.9925 - val_loss: 0.1869 - val_accuracy: 0.9325\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.0443 - accuracy: 0.9819 - val_loss: 0.1363 - val_accuracy: 0.9500\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0295 - accuracy: 0.9931 - val_loss: 0.1627 - val_accuracy: 0.9225\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0310 - accuracy: 0.9906 - val_loss: 0.1235 - val_accuracy: 0.9500\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0403 - accuracy: 0.9875 - val_loss: 0.1575 - val_accuracy: 0.9300\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.0478 - accuracy: 0.9787 - val_loss: 0.1436 - val_accuracy: 0.9350\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.0499 - accuracy: 0.9819 - val_loss: 0.2268 - val_accuracy: 0.9025\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.0427 - accuracy: 0.9819 - val_loss: 0.1607 - val_accuracy: 0.9450\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.0273 - accuracy: 0.9906 - val_loss: 0.2270 - val_accuracy: 0.9275\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0282 - accuracy: 0.9919 - val_loss: 0.1347 - val_accuracy: 0.9500\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 0s 977us/step - loss: 0.0322 - accuracy: 0.9881 - val_loss: 0.1490 - val_accuracy: 0.9225\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.0367 - accuracy: 0.9875 - val_loss: 0.1644 - val_accuracy: 0.9450\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.0338 - accuracy: 0.9900 - val_loss: 0.1682 - val_accuracy: 0.9250\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0390 - accuracy: 0.9844 - val_loss: 0.1515 - val_accuracy: 0.9300\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.0261 - accuracy: 0.9906 - val_loss: 0.1386 - val_accuracy: 0.9325\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.0834 - accuracy: 0.9663 - val_loss: 0.1930 - val_accuracy: 0.9300\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 0s 997us/step - loss: 0.0219 - accuracy: 0.9937 - val_loss: 0.1568 - val_accuracy: 0.9300\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 0s 977us/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.1331 - val_accuracy: 0.9450\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.0240 - accuracy: 0.9937 - val_loss: 0.2030 - val_accuracy: 0.9025\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.0419 - accuracy: 0.9844 - val_loss: 0.1814 - val_accuracy: 0.9225\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.0463 - accuracy: 0.9775 - val_loss: 0.1904 - val_accuracy: 0.9200\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.0301 - accuracy: 0.9887 - val_loss: 0.1750 - val_accuracy: 0.9350\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.1718 - val_accuracy: 0.9300\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.0264 - accuracy: 0.9906 - val_loss: 0.1828 - val_accuracy: 0.9325\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 0s 958us/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.1681 - val_accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.0259 - accuracy: 0.9950 - val_loss: 0.1660 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2399c6f4c50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x_normalized, train_y_oh, epochs=100, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Como salvar o melhor modelo da nossa rede neural?\n",
    "* Nem sempre a ultima época de treinamento contém o melhor modelo.\n",
    "* Salvando nosso modelo, podemos utilzar futuramente sem a necessidade de refazer o treino.\n",
    "\n",
    "### Callbacks\n",
    "* Um callback é um metódo que será executado em um momento especifico (ex: todo fim de época, salvaremos o modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import os\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "check_point_saver_best_acc = ModelCheckpoint(\"./models/best_acc_{val_accuracy}_{epoch}.h5\", monitor='val_accuracy', \n",
    "                                             save_best_only=True, period=1, verbose=1)\n",
    "\n",
    "tensorboard_cb = TensorBoard(log_dir=\"./logs\", write_graph=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  1/200 [..............................] - ETA: 0s - loss: 1.4055 - accuracy: 0.3750WARNING:tensorflow:From c:\\repositorios\\deep_learning_ets\\.venv\\lib\\site-packages\\tensorflow\\python\\ops\\summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "  2/200 [..............................] - ETA: 9s - loss: 1.4131 - accuracy: 0.3125WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_begin` time: 0.0040s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.0938s). Check your callbacks.\n",
      "172/200 [========================>.....] - ETA: 0s - loss: 1.4102 - accuracy: 0.2943\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.31750, saving model to ./models\\best_acc_0.3174999952316284_1.h5\n",
      "200/200 [==============================] - 0s 2ms/step - loss: 1.4080 - accuracy: 0.2944 - val_loss: 1.3949 - val_accuracy: 0.3175\n",
      "Epoch 2/100\n",
      "175/200 [=========================>....] - ETA: 0s - loss: 1.3709 - accuracy: 0.3236\n",
      "Epoch 00002: val_accuracy improved from 0.31750 to 0.34000, saving model to ./models\\best_acc_0.3400000035762787_2.h5\n",
      "200/200 [==============================] - 0s 835us/step - loss: 1.3608 - accuracy: 0.3319 - val_loss: 1.3631 - val_accuracy: 0.3400\n",
      "Epoch 3/100\n",
      "172/200 [========================>.....] - ETA: 0s - loss: 1.3313 - accuracy: 0.3626\n",
      "Epoch 00003: val_accuracy improved from 0.34000 to 0.38000, saving model to ./models\\best_acc_0.3799999952316284_3.h5\n",
      "200/200 [==============================] - 0s 848us/step - loss: 1.3300 - accuracy: 0.3663 - val_loss: 1.3338 - val_accuracy: 0.3800\n",
      "Epoch 4/100\n",
      "165/200 [=======================>......] - ETA: 0s - loss: 1.3033 - accuracy: 0.4053\n",
      "Epoch 00004: val_accuracy improved from 0.38000 to 0.41750, saving model to ./models\\best_acc_0.41749998927116394_4.h5\n",
      "200/200 [==============================] - 0s 884us/step - loss: 1.2996 - accuracy: 0.4131 - val_loss: 1.3038 - val_accuracy: 0.4175\n",
      "Epoch 5/100\n",
      "171/200 [========================>.....] - ETA: 0s - loss: 1.2756 - accuracy: 0.4335\n",
      "Epoch 00005: val_accuracy improved from 0.41750 to 0.45250, saving model to ./models\\best_acc_0.45249998569488525_5.h5\n",
      "200/200 [==============================] - 0s 849us/step - loss: 1.2710 - accuracy: 0.4375 - val_loss: 1.2780 - val_accuracy: 0.4525\n",
      "Epoch 6/100\n",
      "162/200 [=======================>......] - ETA: 0s - loss: 1.2523 - accuracy: 0.4622\n",
      "Epoch 00006: val_accuracy improved from 0.45250 to 0.46750, saving model to ./models\\best_acc_0.4675000011920929_6.h5\n",
      "200/200 [==============================] - 0s 933us/step - loss: 1.2456 - accuracy: 0.4700 - val_loss: 1.2526 - val_accuracy: 0.4675\n",
      "Epoch 7/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 1.2261 - accuracy: 0.4897\n",
      "Epoch 00007: val_accuracy improved from 0.46750 to 0.48000, saving model to ./models\\best_acc_0.47999998927116394_7.h5\n",
      "200/200 [==============================] - 0s 967us/step - loss: 1.2210 - accuracy: 0.4906 - val_loss: 1.2300 - val_accuracy: 0.4800\n",
      "Epoch 8/100\n",
      "148/200 [=====================>........] - ETA: 0s - loss: 1.1950 - accuracy: 0.5228\n",
      "Epoch 00008: val_accuracy improved from 0.48000 to 0.49250, saving model to ./models\\best_acc_0.4925000071525574_8.h5\n",
      "200/200 [==============================] - 0s 972us/step - loss: 1.1983 - accuracy: 0.5194 - val_loss: 1.2092 - val_accuracy: 0.4925\n",
      "Epoch 9/100\n",
      "153/200 [=====================>........] - ETA: 0s - loss: 1.1768 - accuracy: 0.5368\n",
      "Epoch 00009: val_accuracy improved from 0.49250 to 0.49750, saving model to ./models\\best_acc_0.4975000023841858_9.h5\n",
      "200/200 [==============================] - 0s 957us/step - loss: 1.1765 - accuracy: 0.5369 - val_loss: 1.1884 - val_accuracy: 0.4975\n",
      "Epoch 10/100\n",
      "152/200 [=====================>........] - ETA: 0s - loss: 1.1625 - accuracy: 0.5510\n",
      "Epoch 00010: val_accuracy improved from 0.49750 to 0.53000, saving model to ./models\\best_acc_0.5299999713897705_10.h5\n",
      "200/200 [==============================] - 0s 957us/step - loss: 1.1564 - accuracy: 0.5537 - val_loss: 1.1695 - val_accuracy: 0.5300\n",
      "Epoch 11/100\n",
      "152/200 [=====================>........] - ETA: 0s - loss: 1.1335 - accuracy: 0.5707\n",
      "Epoch 00011: val_accuracy improved from 0.53000 to 0.55500, saving model to ./models\\best_acc_0.5550000071525574_11.h5\n",
      "200/200 [==============================] - 0s 938us/step - loss: 1.1372 - accuracy: 0.5669 - val_loss: 1.1516 - val_accuracy: 0.5550\n",
      "Epoch 12/100\n",
      "149/200 [=====================>........] - ETA: 0s - loss: 1.1195 - accuracy: 0.5797\n",
      "Epoch 00012: val_accuracy improved from 0.55500 to 0.55750, saving model to ./models\\best_acc_0.5575000047683716_12.h5\n",
      "200/200 [==============================] - 0s 963us/step - loss: 1.1193 - accuracy: 0.5831 - val_loss: 1.1359 - val_accuracy: 0.5575\n",
      "Epoch 13/100\n",
      "147/200 [=====================>........] - ETA: 0s - loss: 1.0961 - accuracy: 0.5884\n",
      "Epoch 00013: val_accuracy did not improve from 0.55750\n",
      "200/200 [==============================] - 0s 973us/step - loss: 1.1022 - accuracy: 0.5881 - val_loss: 1.1215 - val_accuracy: 0.5525\n",
      "Epoch 14/100\n",
      "153/200 [=====================>........] - ETA: 0s - loss: 1.0918 - accuracy: 0.5891\n",
      "Epoch 00014: val_accuracy improved from 0.55750 to 0.58000, saving model to ./models\\best_acc_0.5799999833106995_14.h5\n",
      "200/200 [==============================] - 0s 962us/step - loss: 1.0868 - accuracy: 0.6031 - val_loss: 1.1039 - val_accuracy: 0.5800\n",
      "Epoch 15/100\n",
      "149/200 [=====================>........] - ETA: 0s - loss: 1.0735 - accuracy: 0.6141\n",
      "Epoch 00015: val_accuracy did not improve from 0.58000\n",
      "200/200 [==============================] - 0s 933us/step - loss: 1.0715 - accuracy: 0.6125 - val_loss: 1.0898 - val_accuracy: 0.5800\n",
      "Epoch 16/100\n",
      "152/200 [=====================>........] - ETA: 0s - loss: 1.0587 - accuracy: 0.6160\n",
      "Epoch 00016: val_accuracy improved from 0.58000 to 0.59500, saving model to ./models\\best_acc_0.5950000286102295_16.h5\n",
      "200/200 [==============================] - 0s 962us/step - loss: 1.0573 - accuracy: 0.6219 - val_loss: 1.0772 - val_accuracy: 0.5950\n",
      "Epoch 17/100\n",
      "153/200 [=====================>........] - ETA: 0s - loss: 1.0505 - accuracy: 0.6299\n",
      "Epoch 00017: val_accuracy did not improve from 0.59500\n",
      "200/200 [==============================] - 0s 908us/step - loss: 1.0426 - accuracy: 0.6413 - val_loss: 1.0640 - val_accuracy: 0.5825\n",
      "Epoch 18/100\n",
      "147/200 [=====================>........] - ETA: 0s - loss: 1.0342 - accuracy: 0.6216\n",
      "Epoch 00018: val_accuracy did not improve from 0.59500\n",
      "200/200 [==============================] - 0s 987us/step - loss: 1.0307 - accuracy: 0.6263 - val_loss: 1.0515 - val_accuracy: 0.5950\n",
      "Epoch 19/100\n",
      "155/200 [======================>.......] - ETA: 0s - loss: 1.0227 - accuracy: 0.6226\n",
      "Epoch 00019: val_accuracy improved from 0.59500 to 0.61000, saving model to ./models\\best_acc_0.6100000143051147_19.h5\n",
      "200/200 [==============================] - 0s 923us/step - loss: 1.0180 - accuracy: 0.6319 - val_loss: 1.0392 - val_accuracy: 0.6100\n",
      "Epoch 20/100\n",
      "149/200 [=====================>........] - ETA: 0s - loss: 1.0073 - accuracy: 0.6351\n",
      "Epoch 00020: val_accuracy improved from 0.61000 to 0.61500, saving model to ./models\\best_acc_0.6150000095367432_20.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 1.0055 - accuracy: 0.6425 - val_loss: 1.0292 - val_accuracy: 0.6150\n",
      "Epoch 21/100\n",
      "139/200 [===================>..........] - ETA: 0s - loss: 0.9931 - accuracy: 0.6646\n",
      "Epoch 00021: val_accuracy improved from 0.61500 to 0.63000, saving model to ./models\\best_acc_0.6299999952316284_21.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9943 - accuracy: 0.6569 - val_loss: 1.0179 - val_accuracy: 0.6300\n",
      "Epoch 22/100\n",
      "137/200 [===================>..........] - ETA: 0s - loss: 0.9802 - accuracy: 0.6661\n",
      "Epoch 00022: val_accuracy did not improve from 0.63000\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.9834 - accuracy: 0.6581 - val_loss: 1.0081 - val_accuracy: 0.6250\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/200 [======================>.......] - ETA: 0s - loss: 0.9806 - accuracy: 0.6550\n",
      "Epoch 00023: val_accuracy did not improve from 0.63000\n",
      "200/200 [==============================] - 0s 938us/step - loss: 0.9733 - accuracy: 0.6637 - val_loss: 0.9973 - val_accuracy: 0.6225\n",
      "Epoch 24/100\n",
      "196/200 [============================>.] - ETA: 0s - loss: 0.9641 - accuracy: 0.6677\n",
      "Epoch 00024: val_accuracy did not improve from 0.63000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9628 - accuracy: 0.6675 - val_loss: 0.9893 - val_accuracy: 0.6250\n",
      "Epoch 25/100\n",
      "133/200 [==================>...........] - ETA: 0s - loss: 0.9507 - accuracy: 0.6645\n",
      "Epoch 00025: val_accuracy did not improve from 0.63000\n",
      "200/200 [==============================] - 0s 992us/step - loss: 0.9526 - accuracy: 0.6719 - val_loss: 0.9812 - val_accuracy: 0.6125\n",
      "Epoch 26/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.9383 - accuracy: 0.6714\n",
      "Epoch 00026: val_accuracy improved from 0.63000 to 0.64250, saving model to ./models\\best_acc_0.6424999833106995_26.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.9435 - accuracy: 0.6706 - val_loss: 0.9706 - val_accuracy: 0.6425\n",
      "Epoch 27/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.9380 - accuracy: 0.6938\n",
      "Epoch 00027: val_accuracy did not improve from 0.64250\n",
      "200/200 [==============================] - 0s 977us/step - loss: 0.9341 - accuracy: 0.6913 - val_loss: 0.9618 - val_accuracy: 0.6275\n",
      "Epoch 28/100\n",
      "143/200 [====================>.........] - ETA: 0s - loss: 0.9277 - accuracy: 0.6853\n",
      "Epoch 00028: val_accuracy did not improve from 0.64250\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.9258 - accuracy: 0.6844 - val_loss: 0.9526 - val_accuracy: 0.6325\n",
      "Epoch 29/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.9153 - accuracy: 0.6995\n",
      "Epoch 00029: val_accuracy did not improve from 0.64250\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.9174 - accuracy: 0.6963 - val_loss: 0.9451 - val_accuracy: 0.6375\n",
      "Epoch 30/100\n",
      "148/200 [=====================>........] - ETA: 0s - loss: 0.9055 - accuracy: 0.7035\n",
      "Epoch 00030: val_accuracy did not improve from 0.64250\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.9094 - accuracy: 0.6938 - val_loss: 0.9371 - val_accuracy: 0.6350\n",
      "Epoch 31/100\n",
      "152/200 [=====================>........] - ETA: 0s - loss: 0.8935 - accuracy: 0.7064\n",
      "Epoch 00031: val_accuracy did not improve from 0.64250\n",
      "200/200 [==============================] - 0s 898us/step - loss: 0.9012 - accuracy: 0.6963 - val_loss: 0.9298 - val_accuracy: 0.6350\n",
      "Epoch 32/100\n",
      "147/200 [=====================>........] - ETA: 0s - loss: 0.8882 - accuracy: 0.6990\n",
      "Epoch 00032: val_accuracy improved from 0.64250 to 0.66750, saving model to ./models\\best_acc_0.6675000190734863_32.h5\n",
      "200/200 [==============================] - 0s 978us/step - loss: 0.8935 - accuracy: 0.6944 - val_loss: 0.9220 - val_accuracy: 0.6675\n",
      "Epoch 33/100\n",
      "150/200 [=====================>........] - ETA: 0s - loss: 0.8854 - accuracy: 0.7217\n",
      "Epoch 00033: val_accuracy did not improve from 0.66750\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.8867 - accuracy: 0.7075 - val_loss: 0.9152 - val_accuracy: 0.6650\n",
      "Epoch 34/100\n",
      "154/200 [======================>.......] - ETA: 0s - loss: 0.8856 - accuracy: 0.6948\n",
      "Epoch 00034: val_accuracy did not improve from 0.66750\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.8792 - accuracy: 0.7069 - val_loss: 0.9090 - val_accuracy: 0.6475\n",
      "Epoch 35/100\n",
      "137/200 [===================>..........] - ETA: 0s - loss: 0.8719 - accuracy: 0.7099\n",
      "Epoch 00035: val_accuracy did not improve from 0.66750\n",
      "200/200 [==============================] - 0s 988us/step - loss: 0.8719 - accuracy: 0.7063 - val_loss: 0.9021 - val_accuracy: 0.6450\n",
      "Epoch 36/100\n",
      "135/200 [===================>..........] - ETA: 0s - loss: 0.8701 - accuracy: 0.7148\n",
      "Epoch 00036: val_accuracy did not improve from 0.66750\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8656 - accuracy: 0.7163 - val_loss: 0.8949 - val_accuracy: 0.6525\n",
      "Epoch 37/100\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.8577 - accuracy: 0.7102\n",
      "Epoch 00037: val_accuracy did not improve from 0.66750\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8588 - accuracy: 0.7106 - val_loss: 0.8902 - val_accuracy: 0.6475\n",
      "Epoch 38/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.8521 - accuracy: 0.7155\n",
      "Epoch 00038: val_accuracy improved from 0.66750 to 0.67000, saving model to ./models\\best_acc_0.6700000166893005_38.h5\n",
      "200/200 [==============================] - 0s 987us/step - loss: 0.8522 - accuracy: 0.7163 - val_loss: 0.8834 - val_accuracy: 0.6700\n",
      "Epoch 39/100\n",
      "198/200 [============================>.] - ETA: 0s - loss: 0.8470 - accuracy: 0.7222\n",
      "Epoch 00039: val_accuracy improved from 0.67000 to 0.68000, saving model to ./models\\best_acc_0.6800000071525574_39.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8464 - accuracy: 0.7225 - val_loss: 0.8766 - val_accuracy: 0.6800\n",
      "Epoch 40/100\n",
      "129/200 [==================>...........] - ETA: 0s - loss: 0.8451 - accuracy: 0.7103\n",
      "Epoch 00040: val_accuracy improved from 0.68000 to 0.68250, saving model to ./models\\best_acc_0.6825000047683716_40.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8398 - accuracy: 0.7181 - val_loss: 0.8702 - val_accuracy: 0.6825\n",
      "Epoch 41/100\n",
      "135/200 [===================>..........] - ETA: 0s - loss: 0.8373 - accuracy: 0.7176\n",
      "Epoch 00041: val_accuracy improved from 0.68250 to 0.70000, saving model to ./models\\best_acc_0.699999988079071_41.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8345 - accuracy: 0.7194 - val_loss: 0.8643 - val_accuracy: 0.7000\n",
      "Epoch 42/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.8347 - accuracy: 0.7252\n",
      "Epoch 00042: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.8289 - accuracy: 0.7231 - val_loss: 0.8588 - val_accuracy: 0.7000\n",
      "Epoch 43/100\n",
      "190/200 [===========================>..] - ETA: 0s - loss: 0.8236 - accuracy: 0.7296\n",
      "Epoch 00043: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8223 - accuracy: 0.7281 - val_loss: 0.8545 - val_accuracy: 0.6775\n",
      "Epoch 44/100\n",
      "143/200 [====================>.........] - ETA: 0s - loss: 0.8177 - accuracy: 0.7229\n",
      "Epoch 00044: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.8169 - accuracy: 0.7269 - val_loss: 0.8484 - val_accuracy: 0.6875\n",
      "Epoch 45/100\n",
      "192/200 [===========================>..] - ETA: 0s - loss: 0.8136 - accuracy: 0.7350\n",
      "Epoch 00045: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.8118 - accuracy: 0.7350 - val_loss: 0.8445 - val_accuracy: 0.6825\n",
      "Epoch 46/100\n",
      "144/200 [====================>.........] - ETA: 0s - loss: 0.8043 - accuracy: 0.7413\n",
      "Epoch 00046: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 928us/step - loss: 0.8068 - accuracy: 0.7412 - val_loss: 0.8410 - val_accuracy: 0.6850\n",
      "Epoch 47/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.8044 - accuracy: 0.7397\n",
      "Epoch 00047: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.8010 - accuracy: 0.7419 - val_loss: 0.8345 - val_accuracy: 0.6875\n",
      "Epoch 48/100\n",
      "151/200 [=====================>........] - ETA: 0s - loss: 0.7900 - accuracy: 0.7310\n",
      "Epoch 00048: val_accuracy did not improve from 0.70000\n",
      "200/200 [==============================] - 0s 903us/step - loss: 0.7972 - accuracy: 0.7287 - val_loss: 0.8295 - val_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.7987 - accuracy: 0.7323\n",
      "Epoch 00049: val_accuracy improved from 0.70000 to 0.70500, saving model to ./models\\best_acc_0.7049999833106995_49.h5\n",
      "200/200 [==============================] - 0s 993us/step - loss: 0.7920 - accuracy: 0.7419 - val_loss: 0.8241 - val_accuracy: 0.7050\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154/200 [======================>.......] - ETA: 0s - loss: 0.7800 - accuracy: 0.7435\n",
      "Epoch 00050: val_accuracy improved from 0.70500 to 0.71250, saving model to ./models\\best_acc_0.7124999761581421_50.h5\n",
      "200/200 [==============================] - 0s 923us/step - loss: 0.7873 - accuracy: 0.7387 - val_loss: 0.8191 - val_accuracy: 0.7125\n",
      "Epoch 51/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.7750 - accuracy: 0.7440\n",
      "Epoch 00051: val_accuracy improved from 0.71250 to 0.72250, saving model to ./models\\best_acc_0.7225000262260437_51.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7824 - accuracy: 0.7425 - val_loss: 0.8139 - val_accuracy: 0.7225\n",
      "Epoch 52/100\n",
      "188/200 [===========================>..] - ETA: 0s - loss: 0.7790 - accuracy: 0.7540\n",
      "Epoch 00052: val_accuracy did not improve from 0.72250\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7784 - accuracy: 0.7519 - val_loss: 0.8094 - val_accuracy: 0.7200\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7506\n",
      "Epoch 00053: val_accuracy did not improve from 0.72250\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7735 - accuracy: 0.7506 - val_loss: 0.8061 - val_accuracy: 0.7025\n",
      "Epoch 54/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.7644 - accuracy: 0.7518\n",
      "Epoch 00054: val_accuracy did not improve from 0.72250\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.7699 - accuracy: 0.7456 - val_loss: 0.8030 - val_accuracy: 0.7075\n",
      "Epoch 55/100\n",
      "175/200 [=========================>....] - ETA: 0s - loss: 0.7629 - accuracy: 0.7564\n",
      "Epoch 00055: val_accuracy improved from 0.72250 to 0.73750, saving model to ./models\\best_acc_0.737500011920929_55.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7650 - accuracy: 0.7500 - val_loss: 0.7976 - val_accuracy: 0.7375\n",
      "Epoch 56/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.7679 - accuracy: 0.7518\n",
      "Epoch 00056: val_accuracy did not improve from 0.73750\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.7605 - accuracy: 0.7581 - val_loss: 0.7942 - val_accuracy: 0.7075\n",
      "Epoch 57/100\n",
      "144/200 [====================>.........] - ETA: 0s - loss: 0.7582 - accuracy: 0.7500\n",
      "Epoch 00057: val_accuracy did not improve from 0.73750\n",
      "200/200 [==============================] - 0s 913us/step - loss: 0.7572 - accuracy: 0.7500 - val_loss: 0.7901 - val_accuracy: 0.7125\n",
      "Epoch 58/100\n",
      "139/200 [===================>..........] - ETA: 0s - loss: 0.7455 - accuracy: 0.7545\n",
      "Epoch 00058: val_accuracy improved from 0.73750 to 0.74000, saving model to ./models\\best_acc_0.7400000095367432_58.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.7550 - val_loss: 0.7857 - val_accuracy: 0.7400\n",
      "Epoch 59/100\n",
      "143/200 [====================>.........] - ETA: 0s - loss: 0.7536 - accuracy: 0.7456\n",
      "Epoch 00059: val_accuracy did not improve from 0.74000\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.7491 - accuracy: 0.7513 - val_loss: 0.7816 - val_accuracy: 0.7350\n",
      "Epoch 60/100\n",
      "144/200 [====================>.........] - ETA: 0s - loss: 0.7468 - accuracy: 0.7604\n",
      "Epoch 00060: val_accuracy did not improve from 0.74000\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.7454 - accuracy: 0.7563 - val_loss: 0.7774 - val_accuracy: 0.7325\n",
      "Epoch 61/100\n",
      "149/200 [=====================>........] - ETA: 0s - loss: 0.7395 - accuracy: 0.7701\n",
      "Epoch 00061: val_accuracy did not improve from 0.74000\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.7414 - accuracy: 0.7644 - val_loss: 0.7745 - val_accuracy: 0.7175\n",
      "Epoch 62/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.7313 - accuracy: 0.7696\n",
      "Epoch 00062: val_accuracy did not improve from 0.74000\n",
      "200/200 [==============================] - 0s 983us/step - loss: 0.7379 - accuracy: 0.7619 - val_loss: 0.7705 - val_accuracy: 0.7325\n",
      "Epoch 63/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.7318 - accuracy: 0.7560\n",
      "Epoch 00063: val_accuracy improved from 0.74000 to 0.74250, saving model to ./models\\best_acc_0.7425000071525574_63.h5\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.7345 - accuracy: 0.7606 - val_loss: 0.7676 - val_accuracy: 0.7425\n",
      "Epoch 64/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.7227 - accuracy: 0.7784\n",
      "Epoch 00064: val_accuracy improved from 0.74250 to 0.74500, saving model to ./models\\best_acc_0.7450000047683716_64.h5\n",
      "200/200 [==============================] - 0s 982us/step - loss: 0.7313 - accuracy: 0.7675 - val_loss: 0.7658 - val_accuracy: 0.7450\n",
      "Epoch 65/100\n",
      "142/200 [====================>.........] - ETA: 0s - loss: 0.7304 - accuracy: 0.7597\n",
      "Epoch 00065: val_accuracy did not improve from 0.74500\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.7277 - accuracy: 0.7663 - val_loss: 0.7598 - val_accuracy: 0.7450\n",
      "Epoch 66/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.7218 - accuracy: 0.7696\n",
      "Epoch 00066: val_accuracy improved from 0.74500 to 0.75250, saving model to ./models\\best_acc_0.7524999976158142_66.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.7694 - val_loss: 0.7574 - val_accuracy: 0.7525\n",
      "Epoch 67/100\n",
      "134/200 [===================>..........] - ETA: 0s - loss: 0.7280 - accuracy: 0.7771\n",
      "Epoch 00067: val_accuracy did not improve from 0.75250\n",
      "200/200 [==============================] - 0s 968us/step - loss: 0.7205 - accuracy: 0.7750 - val_loss: 0.7533 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "151/200 [=====================>........] - ETA: 0s - loss: 0.7146 - accuracy: 0.7724\n",
      "Epoch 00068: val_accuracy did not improve from 0.75250\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.7175 - accuracy: 0.7700 - val_loss: 0.7502 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.7073 - accuracy: 0.7917\n",
      "Epoch 00069: val_accuracy did not improve from 0.75250\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.7142 - accuracy: 0.7750 - val_loss: 0.7468 - val_accuracy: 0.7450\n",
      "Epoch 70/100\n",
      "138/200 [===================>..........] - ETA: 0s - loss: 0.7100 - accuracy: 0.7745\n",
      "Epoch 00070: val_accuracy did not improve from 0.75250\n",
      "200/200 [==============================] - 0s 968us/step - loss: 0.7106 - accuracy: 0.7750 - val_loss: 0.7436 - val_accuracy: 0.7525\n",
      "Epoch 71/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.7062 - accuracy: 0.7757\n",
      "Epoch 00071: val_accuracy improved from 0.75250 to 0.76000, saving model to ./models\\best_acc_0.7599999904632568_71.h5\n",
      "200/200 [==============================] - 0s 977us/step - loss: 0.7080 - accuracy: 0.7775 - val_loss: 0.7404 - val_accuracy: 0.7600\n",
      "Epoch 72/100\n",
      "139/200 [===================>..........] - ETA: 0s - loss: 0.7041 - accuracy: 0.7842\n",
      "Epoch 00072: val_accuracy did not improve from 0.76000\n",
      "200/200 [==============================] - 0s 953us/step - loss: 0.7043 - accuracy: 0.7750 - val_loss: 0.7370 - val_accuracy: 0.7575\n",
      "Epoch 73/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.7051 - accuracy: 0.7663\n",
      "Epoch 00073: val_accuracy did not improve from 0.76000\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.7015 - accuracy: 0.7756 - val_loss: 0.7343 - val_accuracy: 0.7600\n",
      "Epoch 74/100\n",
      "140/200 [====================>.........] - ETA: 0s - loss: 0.7066 - accuracy: 0.7705\n",
      "Epoch 00074: val_accuracy did not improve from 0.76000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.7775 - val_loss: 0.7319 - val_accuracy: 0.7525\n",
      "Epoch 75/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.6874 - accuracy: 0.7810\n",
      "Epoch 00075: val_accuracy did not improve from 0.76000\n",
      "200/200 [==============================] - 0s 962us/step - loss: 0.6958 - accuracy: 0.7794 - val_loss: 0.7291 - val_accuracy: 0.7600\n",
      "Epoch 76/100\n",
      "139/200 [===================>..........] - ETA: 0s - loss: 0.6937 - accuracy: 0.7743\n",
      "Epoch 00076: val_accuracy improved from 0.76000 to 0.76250, saving model to ./models\\best_acc_0.762499988079071_76.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.7819 - val_loss: 0.7253 - val_accuracy: 0.7625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.6995 - accuracy: 0.7793\n",
      "Epoch 00077: val_accuracy did not improve from 0.76250\n",
      "200/200 [==============================] - 0s 957us/step - loss: 0.6904 - accuracy: 0.7850 - val_loss: 0.7224 - val_accuracy: 0.7600\n",
      "Epoch 78/100\n",
      "134/200 [===================>..........] - ETA: 0s - loss: 0.7001 - accuracy: 0.7705\n",
      "Epoch 00078: val_accuracy improved from 0.76250 to 0.76500, saving model to ./models\\best_acc_0.7649999856948853_78.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6873 - accuracy: 0.7856 - val_loss: 0.7199 - val_accuracy: 0.7650\n",
      "Epoch 79/100\n",
      "157/200 [======================>.......] - ETA: 0s - loss: 0.6824 - accuracy: 0.7914\n",
      "Epoch 00079: val_accuracy improved from 0.76500 to 0.77000, saving model to ./models\\best_acc_0.7699999809265137_79.h5\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.6841 - accuracy: 0.7881 - val_loss: 0.7172 - val_accuracy: 0.7700\n",
      "Epoch 80/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.6852 - accuracy: 0.7808\n",
      "Epoch 00080: val_accuracy did not improve from 0.77000\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.6814 - accuracy: 0.7850 - val_loss: 0.7146 - val_accuracy: 0.7675\n",
      "Epoch 81/100\n",
      "153/200 [=====================>........] - ETA: 0s - loss: 0.6768 - accuracy: 0.7933\n",
      "Epoch 00081: val_accuracy did not improve from 0.77000\n",
      "200/200 [==============================] - 0s 918us/step - loss: 0.6794 - accuracy: 0.7925 - val_loss: 0.7115 - val_accuracy: 0.7600\n",
      "Epoch 82/100\n",
      "152/200 [=====================>........] - ETA: 0s - loss: 0.6759 - accuracy: 0.7911\n",
      "Epoch 00082: val_accuracy did not improve from 0.77000\n",
      "200/200 [==============================] - 0s 953us/step - loss: 0.6767 - accuracy: 0.7900 - val_loss: 0.7094 - val_accuracy: 0.7675\n",
      "Epoch 83/100\n",
      "144/200 [====================>.........] - ETA: 0s - loss: 0.6691 - accuracy: 0.7960\n",
      "Epoch 00083: val_accuracy improved from 0.77000 to 0.77750, saving model to ./models\\best_acc_0.7774999737739563_83.h5\n",
      "200/200 [==============================] - 0s 988us/step - loss: 0.6738 - accuracy: 0.7869 - val_loss: 0.7078 - val_accuracy: 0.7775\n",
      "Epoch 84/100\n",
      "142/200 [====================>.........] - ETA: 0s - loss: 0.6660 - accuracy: 0.7870\n",
      "Epoch 00084: val_accuracy did not improve from 0.77750\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.6718 - accuracy: 0.7856 - val_loss: 0.7047 - val_accuracy: 0.7700\n",
      "Epoch 85/100\n",
      "136/200 [===================>..........] - ETA: 0s - loss: 0.6673 - accuracy: 0.7941\n",
      "Epoch 00085: val_accuracy did not improve from 0.77750\n",
      "200/200 [==============================] - 0s 988us/step - loss: 0.6686 - accuracy: 0.7912 - val_loss: 0.7013 - val_accuracy: 0.7725\n",
      "Epoch 86/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.6653 - accuracy: 0.7911\n",
      "Epoch 00086: val_accuracy improved from 0.77750 to 0.78250, saving model to ./models\\best_acc_0.7825000286102295_86.h5\n",
      "200/200 [==============================] - 0s 973us/step - loss: 0.6665 - accuracy: 0.7912 - val_loss: 0.7008 - val_accuracy: 0.7825\n",
      "Epoch 87/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.6643 - accuracy: 0.7979\n",
      "Epoch 00087: val_accuracy improved from 0.78250 to 0.79000, saving model to ./models\\best_acc_0.7900000214576721_87.h5\n",
      "200/200 [==============================] - 0s 988us/step - loss: 0.6640 - accuracy: 0.7950 - val_loss: 0.6972 - val_accuracy: 0.7900\n",
      "Epoch 88/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.6709 - accuracy: 0.7851\n",
      "Epoch 00088: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 913us/step - loss: 0.6616 - accuracy: 0.7944 - val_loss: 0.6942 - val_accuracy: 0.7800\n",
      "Epoch 89/100\n",
      "146/200 [====================>.........] - ETA: 0s - loss: 0.6628 - accuracy: 0.7954\n",
      "Epoch 00089: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 933us/step - loss: 0.6595 - accuracy: 0.7975 - val_loss: 0.6923 - val_accuracy: 0.7775\n",
      "Epoch 90/100\n",
      "150/200 [=====================>........] - ETA: 0s - loss: 0.6648 - accuracy: 0.8000\n",
      "Epoch 00090: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 943us/step - loss: 0.6568 - accuracy: 0.8012 - val_loss: 0.6902 - val_accuracy: 0.7800\n",
      "Epoch 91/100\n",
      "145/200 [====================>.........] - ETA: 0s - loss: 0.6527 - accuracy: 0.8026\n",
      "Epoch 00091: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 928us/step - loss: 0.6543 - accuracy: 0.8000 - val_loss: 0.6877 - val_accuracy: 0.7850\n",
      "Epoch 92/100\n",
      "147/200 [=====================>........] - ETA: 0s - loss: 0.6441 - accuracy: 0.8087\n",
      "Epoch 00092: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 952us/step - loss: 0.6523 - accuracy: 0.8006 - val_loss: 0.6853 - val_accuracy: 0.7775\n",
      "Epoch 93/100\n",
      "139/200 [===================>..........] - ETA: 0s - loss: 0.6482 - accuracy: 0.8022\n",
      "Epoch 00093: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 972us/step - loss: 0.6502 - accuracy: 0.8000 - val_loss: 0.6837 - val_accuracy: 0.7850\n",
      "Epoch 94/100\n",
      "142/200 [====================>.........] - ETA: 0s - loss: 0.6386 - accuracy: 0.7958\n",
      "Epoch 00094: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.6479 - accuracy: 0.7937 - val_loss: 0.6808 - val_accuracy: 0.7900\n",
      "Epoch 95/100\n",
      "189/200 [===========================>..] - ETA: 0s - loss: 0.6447 - accuracy: 0.8082\n",
      "Epoch 00095: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.8044 - val_loss: 0.6784 - val_accuracy: 0.7900\n",
      "Epoch 96/100\n",
      "190/200 [===========================>..] - ETA: 0s - loss: 0.6430 - accuracy: 0.8092\n",
      "Epoch 00096: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6438 - accuracy: 0.8112 - val_loss: 0.6773 - val_accuracy: 0.7900\n",
      "Epoch 97/100\n",
      "151/200 [=====================>........] - ETA: 0s - loss: 0.6423 - accuracy: 0.8013\n",
      "Epoch 00097: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 908us/step - loss: 0.6410 - accuracy: 0.8000 - val_loss: 0.6762 - val_accuracy: 0.7825\n",
      "Epoch 98/100\n",
      "141/200 [====================>.........] - ETA: 0s - loss: 0.6462 - accuracy: 0.8023\n",
      "Epoch 00098: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 948us/step - loss: 0.6396 - accuracy: 0.8081 - val_loss: 0.6727 - val_accuracy: 0.7900\n",
      "Epoch 99/100\n",
      "143/200 [====================>.........] - ETA: 0s - loss: 0.6332 - accuracy: 0.8164\n",
      "Epoch 00099: val_accuracy did not improve from 0.79000\n",
      "200/200 [==============================] - 0s 967us/step - loss: 0.6374 - accuracy: 0.8050 - val_loss: 0.6711 - val_accuracy: 0.7900\n",
      "Epoch 100/100\n",
      "138/200 [===================>..........] - ETA: 0s - loss: 0.6331 - accuracy: 0.8107\n",
      "Epoch 00100: val_accuracy improved from 0.79000 to 0.80000, saving model to ./models\\best_acc_0.800000011920929_100.h5\n",
      "200/200 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.8075 - val_loss: 0.6691 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2399d8e9e80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(20))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x_normalized, train_y_oh, epochs=100, batch_size=8, validation_split=0.2,\n",
    "         callbacks=[check_point_saver_best_acc, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/my_last_epoch_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferência\n",
    "* Como carregar e utilizar um modelo treinado?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"./models/my_last_epoch_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregar dados de testes (Sem label de saída)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "data_test = pd.read_csv(\"./mobile_test.csv\")\n",
    "test_x = data_test.values[..., 1:]\n",
    "print(test_x.shape)\n",
    "\n",
    "test_x_normalized = normalizer.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1635288e-04 4.2644490e-02 4.2655706e-01 5.3028202e-01]\n",
      " [2.0590096e-04 6.3739389e-02 4.3546784e-01 5.0058687e-01]\n",
      " [1.5615023e-02 3.4362218e-01 3.2567388e-01 3.1508884e-01]\n",
      " ...\n",
      " [1.7765015e-01 4.6321824e-01 2.6919729e-01 8.9934409e-02]\n",
      " [2.3116447e-02 2.6907814e-01 4.1089186e-01 2.9691356e-01]\n",
      " [4.2133997e-03 1.2177369e-01 5.5932248e-01 3.1469041e-01]]\n",
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "pred_y = model.predict(test_x_normalized)\n",
    "print(pred_y)\n",
    "print(np.round(pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
